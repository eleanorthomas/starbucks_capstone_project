{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capstone Project - Portfolio Exercise Starbucks\n",
    " \n",
    "## Project Definition \n",
    "\n",
    "The following is adapted from the Udacity exercise description.\n",
    "\n",
    "### Background Information\n",
    "\n",
    "The dataset provided in this portfolio exercise was originally used as a take-home assignment provided by Starbucks for their candidates. The data for this exercise consists of about 120,000 data points split in 2:1 ratio among training and test files. Each data point includes one column indicating whether or not an individual was sent a promotion for a specific product, and one column indicating whether or not that individual eventually purchased that product. Each individual also had seven additional features associated with them.\n",
    "\n",
    "The training data is provided below.\n",
    "\n",
    "For a full description of what Starbucks provides to candidates see the [instructions available here](https://drive.google.com/open?id=18klca9Sef1Rs6q8DW4l7o349r8B70qXM).\n",
    "\n",
    "## Problem Statement\n",
    "\n",
    "The task is to use the training data to understand what patterns in V1-V7 (the training features) to indicate that a promotion should be provided to a user. The expected solution will be a function called **promotion_strategy**, likely utilizing some form of machine learning classification strategy in order to classify users into two categories: \"send promotion\" and \"do not send promotion\". The results will be compared with Starbucks's solution (see \"Testing & Evaluation\").\n",
    "\n",
    "## Metrics\n",
    "\n",
    "### Optimization Metrics\n",
    "\n",
    "Specifically, the goal is to maximize the following metrics:\n",
    "\n",
    "* **Incremental Response Rate (IRR)** \n",
    "\n",
    "Ratio of the number of purchasers in the promotion group to the total number of customers in the promotion group minus the ratio of the number of purchasers in the non-promotional group to the total number of customers in the non-promotional group.\n",
    "\n",
    "* **Net Incremental Revenue (NIR)**\n",
    "\n",
    "The total number of purchasers that received the promotion times 10 minus the number of promotions given times 0.15 minus the number of purchasers who were not given the promotion times 10.\n",
    "\n",
    "### Testing & Evaluation Metrics\n",
    "\n",
    "The success of the optimization strategy will be evaluated against Starbucks' promotion strategy. The strategy will be implemented within the **promotion_strategy** function and passed to the **test_results** function for evaluation.\n",
    "\n",
    "There are four possible outomes relative to past data:\n",
    "\n",
    "Table of actual promotion vs. predicted promotion customers.  \n",
    "\n",
    "```\n",
    "\n",
    "|   | Actual      |     |    | \n",
    "|---|-------------|-----|----|\n",
    "| Predicted       | Yes | No |  \n",
    "| Yes             | I   | II |  \n",
    "| No              | III | IV | \n",
    "```\n",
    "\n",
    "The metrics will only be compared for the individuals which Starbucks predicts should obtain the promotion - that is quadrants I and II here. Since the first set of individuals that receive the promotion (in the training set) receive it randomly, we can expect that quadrants I and II will have approximately equal participants.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis\n",
    "\n",
    "First we will read in the data below and examine how each variable or combination of variables along with a promotion influences the chance of purchasing. We will include visualizations of the relationships between variables, promotions and purchasing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in packages\n",
    "from itertools import combinations\n",
    "\n",
    "from test_results import test_results, score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import sklearn as sk\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "%matplotlib inline\n",
    "\n",
    "# load in the data\n",
    "train_data = pd.read_csv('./data/training.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Exploration\n",
    "\n",
    "The first steps for data exploration are to view a sample of the data and calculate some descriptive statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Promotion</th>\n",
       "      <th>purchase</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>30.443518</td>\n",
       "      <td>-1.165083</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>32.159350</td>\n",
       "      <td>-0.645617</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>30.431659</td>\n",
       "      <td>0.133583</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26.588914</td>\n",
       "      <td>-0.212728</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>28.044332</td>\n",
       "      <td>-0.385883</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID Promotion  purchase  V1         V2        V3  V4  V5  V6  V7\n",
       "0   1        No         0   2  30.443518 -1.165083   1   1   3   2\n",
       "1   3        No         0   3  32.159350 -0.645617   2   3   2   2\n",
       "2   4        No         0   2  30.431659  0.133583   1   1   4   2\n",
       "3   5        No         0   0  26.588914 -0.212728   2   1   4   2\n",
       "4   8       Yes         0   3  28.044332 -0.385883   1   1   2   2"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Yes    42364\n",
       "No     42170\n",
       "Name: Promotion, dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.Promotion.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>purchase</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>84534.000000</td>\n",
       "      <td>84534.000000</td>\n",
       "      <td>84534.000000</td>\n",
       "      <td>84534.000000</td>\n",
       "      <td>84534.000000</td>\n",
       "      <td>84534.000000</td>\n",
       "      <td>84534.000000</td>\n",
       "      <td>84534.000000</td>\n",
       "      <td>84534.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>62970.972413</td>\n",
       "      <td>0.012303</td>\n",
       "      <td>1.500662</td>\n",
       "      <td>29.973600</td>\n",
       "      <td>0.000190</td>\n",
       "      <td>1.679608</td>\n",
       "      <td>2.327643</td>\n",
       "      <td>2.502898</td>\n",
       "      <td>1.701694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>36418.440539</td>\n",
       "      <td>0.110234</td>\n",
       "      <td>0.868234</td>\n",
       "      <td>5.010626</td>\n",
       "      <td>1.000485</td>\n",
       "      <td>0.466630</td>\n",
       "      <td>0.841167</td>\n",
       "      <td>1.117349</td>\n",
       "      <td>0.457517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.104007</td>\n",
       "      <td>-1.684550</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>31467.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>26.591501</td>\n",
       "      <td>-0.905350</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>62827.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>29.979744</td>\n",
       "      <td>-0.039572</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>94438.750000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>33.344593</td>\n",
       "      <td>0.826206</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>126184.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>50.375913</td>\n",
       "      <td>1.691984</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  ID      purchase            V1            V2            V3  \\\n",
       "count   84534.000000  84534.000000  84534.000000  84534.000000  84534.000000   \n",
       "mean    62970.972413      0.012303      1.500662     29.973600      0.000190   \n",
       "std     36418.440539      0.110234      0.868234      5.010626      1.000485   \n",
       "min         1.000000      0.000000      0.000000      7.104007     -1.684550   \n",
       "25%     31467.250000      0.000000      1.000000     26.591501     -0.905350   \n",
       "50%     62827.500000      0.000000      2.000000     29.979744     -0.039572   \n",
       "75%     94438.750000      0.000000      2.000000     33.344593      0.826206   \n",
       "max    126184.000000      1.000000      3.000000     50.375913      1.691984   \n",
       "\n",
       "                 V4            V5            V6            V7  \n",
       "count  84534.000000  84534.000000  84534.000000  84534.000000  \n",
       "mean       1.679608      2.327643      2.502898      1.701694  \n",
       "std        0.466630      0.841167      1.117349      0.457517  \n",
       "min        1.000000      1.000000      1.000000      1.000000  \n",
       "25%        1.000000      2.000000      2.000000      1.000000  \n",
       "50%        2.000000      2.000000      3.000000      2.000000  \n",
       "75%        2.000000      3.000000      4.000000      2.000000  \n",
       "max        2.000000      4.000000      4.000000      2.000000  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization\n",
    "\n",
    "After viewing the descriptive statistics above for the various features V1-V7, it would be helpful also to visualize each of these features as a histogram to get a general sense of how the features are distributed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x360 with 7 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1,7, figsize=(20, 5))\n",
    "ax[0].hist(train_data.V1, bins=10)\n",
    "ax[0].set_title('V1 Histogram')\n",
    "ax[1].hist(train_data.V2, bins=10)\n",
    "ax[1].set_title('V2 Histogram')\n",
    "ax[2].hist(train_data.V3, bins=10)\n",
    "ax[2].set_title('V3 Histogram')\n",
    "ax[3].hist(train_data.V4, bins=10)\n",
    "ax[3].set_title('V4 Histogram')\n",
    "ax[4].hist(train_data.V5, bins=10)\n",
    "ax[4].set_title('V5 Histogram')\n",
    "ax[5].hist(train_data.V6, bins=10)\n",
    "ax[5].set_title('V6 Histogram')\n",
    "ax[6].hist(train_data.V7, bins=10)\n",
    "ax[6].set_title('V7 Histogram')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some observations, based on the descriptive statistics and histograms:\n",
    "    - V1, V4, V5, V6 and V7 appear to be discretely distributed with values rangeing between 0 and 4 depending on the metric.\n",
    "    - V2 appears to be approximately normally distributed around a mean of 30 or so, with standard deviation of about 5.\n",
    "    - V3 appears to be uniformly distributed between approximately -1.7 and 1.7 with mean of around 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step will be to implement the optimization metrics as defined above (IRR and NIR) and calculate the values for Starbucks's solution on the training data to give us a benchmark for our classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_irr(df):\n",
    "    '''\n",
    "    Ratio of the number of purchasers in the promotion group to the total number of customers\n",
    "    in the promotion group minus the ratio of the number of purchasers in the non-promotional\n",
    "    group to the total number of customers in the non-promotional group.\n",
    "    '''\n",
    "    num_purchasers_prom = len(df[(df['Promotion'] == 'Yes') & df['purchase']])\n",
    "    tot_promo = len(df[df['Promotion'] == 'Yes'])\n",
    "    \n",
    "    num_purchasers_noprom = len(df[(df['Promotion'] == 'No') & df['purchase']])\n",
    "    tot_no_promo = len(df[df['Promotion'] == 'No'])\n",
    "    \n",
    "    irr = num_purchasers_prom / tot_promo - num_purchasers_noprom / tot_no_promo\n",
    "    \n",
    "    return irr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.009454547819772702"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_irr(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_nir(df):\n",
    "    '''\n",
    "    The total number of purchasers that received the promotion times 10\n",
    "    minus the number of promotions given times 0.15\n",
    "    minus the number of purchasers who were not given the promotion times 10.\n",
    "    '''\n",
    "\n",
    "    num_purchasers_prom = len(df[(df['Promotion'] == 'Yes') & df['purchase']])\n",
    "    tot_promo = len(df[df['Promotion'] == 'Yes'])\n",
    "    num_purchasers_noprom = len(df[(df['Promotion'] == 'No') & df['purchase']])\n",
    "    \n",
    "    nir = num_purchasers_prom * 10 - tot_promo * 0.15 - num_purchasers_noprom * 10\n",
    "    \n",
    "    return nir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-2334.5999999999995"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_nir(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the IRR for the training set is fairly low, only about 1%, although without industry context, it is unclear whether this is low relative to industry standard. This rate will be taken as our benchmark rate.\n",
    "\n",
    "The NIR is also quite low, with a loss of over $2000 on the campaign. Given that the number of those who receive the promotion and the number who do not are fairly close (42364 vs. 42170), this metric is not skewed by a biased sample, and we would hope to be able to bring it above 0 with our solution, but at least above this benchmark metric of -2334.6."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methodology \n",
    "\n",
    "### Preprocessing\n",
    "\n",
    "Now that we have explored and visualized the data, formulated a strategy and identified benchmarks, we must first preprocess the data in order to prepare it for implementing our strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 84534 entries, 0 to 84533\n",
      "Data columns (total 10 columns):\n",
      "ID           84534 non-null int64\n",
      "Promotion    84534 non-null object\n",
      "purchase     84534 non-null int64\n",
      "V1           84534 non-null int64\n",
      "V2           84534 non-null float64\n",
      "V3           84534 non-null float64\n",
      "V4           84534 non-null int64\n",
      "V5           84534 non-null int64\n",
      "V6           84534 non-null int64\n",
      "V7           84534 non-null int64\n",
      "dtypes: float64(2), int64(7), object(1)\n",
      "memory usage: 6.4+ MB\n"
     ]
    }
   ],
   "source": [
    "train_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 missing values in column ID\n",
      "0 missing values in column Promotion\n",
      "0 missing values in column purchase\n",
      "0 missing values in column V1\n",
      "0 missing values in column V2\n",
      "0 missing values in column V3\n",
      "0 missing values in column V4\n",
      "0 missing values in column V5\n",
      "0 missing values in column V6\n",
      "0 missing values in column V7\n"
     ]
    }
   ],
   "source": [
    "for col in train_data.columns:\n",
    "    print('{} missing values in column {}'.format(train_data[col].isnull().sum(), col))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that there are no missing values in the data, and all of the features are numeric.\n",
    "\n",
    "It is possible that the discrete features should be treated as categorical, but at this stage we cannot know for sure, so we will proceed by treating them as numeric and see where this gets us. We can treat them as categorical and create dummy features later if need be and see if it improves our results.\n",
    "\n",
    "In order to implement a classification strategy, we will need to identify a target variable and consider `V1`-`V7` as our features.\n",
    "\n",
    "We can ignore the `ID` field. Our target variable should be whether or not an individual **should** receive a promotion, which will be modeled as the set of individuals which **did** receive a promotion and **did** purchase as well as those users who **did not** receive a promotion and **did not** purchase. Users who **should not** receive a promotion will be those who **did** receive one and **did not** purchase as well as those who **did** receive one and **did not** purchase.\n",
    "\n",
    "The reasoning behind this model is that those who purchased without receiving a promotion or did not purchase despite receiving one were not positively affected by the promotion enough to purchase, or would have purchased anyway. The others, it can't be said for sure, but there is the possibility that they were either encouraged to purchase based on the promotion or they would have purchased had they received one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['Send Promotion'] = train_data.apply(lambda row: 1 if (row.Promotion == 'Yes' and row.purchase)\n",
    "                                                              or (row.Promotion == 'No' and not row.purchase)\n",
    "                                                            else 0, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = train_data[['V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = train_data[['Send Promotion']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation & Refinement\n",
    "\n",
    "Now that we have explored and preprocessed the data, we will implement and refine our classification strategy for determining who should receive the Starbucks promotion.\n",
    "\n",
    "First we will need to split our training data into two sets, for training and testing our classifier, and create a reusable function which can train a given classifier, generate predictions for the training and testing set, and then calculate scores for each set of predictions as compared to the true value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.25, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_predict(classifier, X_train, y_train, X_test, y_test):\n",
    "    classifier = classifier.fit(X_train, y_train)\n",
    "    \n",
    "    preds_train = classifier.predict(X_train)\n",
    "    preds_test = classifier.predict(X_test)\n",
    "    \n",
    "    acc_train = classifier.score(X_train, y_train)\n",
    "    acc_test = classifier.score(X_test, y_test)\n",
    "    \n",
    "    return preds_train, preds_test, acc_train, acc_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have everything we need to begin classifying. We will attempt classification with the following three classifiers:\n",
    "    - Naive Bayes (GaussianNB)\n",
    "    - RandomForestClassifier\n",
    "    - AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score: 0.5085173501577287; Test score: 0.5092268382700861\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score: 0.9685331230283911; Test score: 0.4940380429639444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score: 0.5136277602523659; Test score: 0.5000473171193338\n"
     ]
    }
   ],
   "source": [
    "classifiers = [GaussianNB(), RandomForestClassifier(), AdaBoostClassifier()]\n",
    "\n",
    "for clf in classifiers:\n",
    "    _, _, acc_train, acc_test = train_predict(clf, X_train, y_train, X_test, y_test)\n",
    "    \n",
    "    print(\"Training score: {}; Test score: {}\".format(acc_train, acc_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see from the results above that our RandomForestClassifier is massively overtraining (with training score ~100% but testing score not much better than chance) and both of the other classifiers do no better than chance.\n",
    "\n",
    "Since the GaussianNB classifier doesn't have much in the way of hyperparameters to optimize, we will attempt to refine and optimize the AdaBoostClassifier to see if we can improve our prediction significantly above chance levels, and more importantly to improve our NIR and IRR metrics over the benchmark values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_classifier = AdaBoostClassifier(n_estimators=300, learning_rate=0.8, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score: 0.5178391167192429; Test score: 0.5030756127566953\n"
     ]
    }
   ],
   "source": [
    "_, _, acc_train, acc_test = train_predict(chosen_classifier, X_train, y_train, X_test, y_test)\n",
    "print(\"Training score: {}; Test score: {}\".format(acc_train, acc_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are not able to do significantly better than chance, regardless of the hyperparameters offered, but let's evaluate our promotion strategy regardless."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def promotion_strategy(df):\n",
    "    '''\n",
    "    INPUT \n",
    "    df - a dataframe with *only* the columns V1 - V7 (same as train_data)\n",
    "\n",
    "    OUTPUT\n",
    "    promotion_df - np.array with the values\n",
    "                   'Yes' or 'No' related to whether or not an \n",
    "                   individual should recieve a promotion \n",
    "                   should be the length of df.shape[0]\n",
    "                \n",
    "    Ex:\n",
    "    INPUT: df\n",
    "    \n",
    "    V1\tV2\t  V3\tV4\tV5\tV6\tV7\n",
    "    2\t30\t-1.1\t1\t1\t3\t2\n",
    "    3\t32\t-0.6\t2\t3\t2\t2\n",
    "    2\t30\t0.13\t1\t1\t4\t2\n",
    "    \n",
    "    OUTPUT: promotion\n",
    "    \n",
    "    array(['Yes', 'Yes', 'No'])\n",
    "    indicating the first two users would recieve the promotion and \n",
    "    the last should not.\n",
    "    '''\n",
    "    \n",
    "    res = chosen_classifier.predict(df[['V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7']])\n",
    "    promotion = np.array([('Yes' if x == 1 else 'No') for x in res])\n",
    "    \n",
    "    return promotion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results - Evaluation & Justification\n",
    "\n",
    "Next we must evaluate our results using the `test_results` function provided and justify our decisions regarding implementation of this particular strategy as opposed to others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nice job!  See how well your strategy worked on our test data below!\n",
      "\n",
      "Your irr with this strategy is 0.01.\n",
      "\n",
      "Your nir with this strategy is -466.85.\n",
      "Approximately, the highest scores obtained at Udacity were: irr of 0.1 and an nir of 300.\n",
      "\n",
      " How did you do?\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.01150240766862869, -466.8499999999999)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_results(promotion_strategy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see from our results, we were able to beat the random-assignment benchmark value for NIR listed above and come in line with the benchmark value for IRR, but did not reach the highest IRR and NIR values obtained at Udacity.\n",
    "\n",
    "The decision to implement a classifier based on the features and target variable defined above was the most natural first attempt, though may not have been the optimal strategy for this project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Finally, we will reflect on the results achieved and identify areas for potential improvement.\n",
    "\n",
    "### Reflection\n",
    "\n",
    "\n",
    "Given that the classifiers implemented did not do much better than chance levels at predicting whether an individual was flagged for promotion, it is not surprising that the results were not phenomenal. It is also very possible that the initial decisions to consider the discrete features as numeric rather than categorical, or how to classify individuals into whether or not they should receive a promotion were not the best choices, but they were simple first-pass assumptions for this project, and the results were still able to beat random-assignment in NIR.\n",
    "\n",
    "### Areas for Improvement\n",
    "\n",
    "The first area for improvement I would attempt would be to define the discrete features as categorical variables and re-attempt classification with the new feature set.\n",
    "\n",
    "The second area for improvement I would consider would be to re-evaluate the definition of the target variable. Perhaps only individuals who received the promotion should be considered for classification, based on whether or not they purchased. Perhaps individuals who did not receive the promotion but purchased anyway should also be considered, and still labeled as \"No\", but individuals who did not receive the promotion and did not purchase should be excluded from the data set, since they do not offer us very much information and were perhaps simply adding noise to the data.\n",
    "\n",
    "The final area for improvement that I would consider would be to do a deeper dive into the classifier models and hyperparameter optimization, to see if there is a better model than the ones considered and possibly employ GridSearch on each of the classifiers to be sure we have the best set of hyperparameters for each. I would only pursue this path after exploring the first two areas of improvement, since a more well-defined problem will always yield better results than a fancy algorithm with noisy data and an ill-defined task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
